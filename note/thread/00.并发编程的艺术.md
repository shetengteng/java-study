## 多线程基础





### 上下文切换

> cpu通过时间片分配算法来循环执行任务，当前任务执行一个时间片后，会切换到下一个任务的时候，需要保存上一个任务的状态，用于下次执行该任务时恢复状态。
>
> 任务从保存到加载的过程，就是一次上下文切换。

- 创建和切换上下文是有开销的，如果频繁切换上下文，有时候串行比并行效率高
- 使用Lmbench3（性能分析工具）测量上下文切换时长
- 使用vmstat测量山下文切换次数
- 如何减少上下文切换
  - 无锁并发编程
    - 使用其他方式避免使用锁，将数据的id通过hash取模，分配到得到不同的数据给不同的线程，避免线程操作相同的数据。
  - cas算法
    - java的Atomic包使用cas算法更新数据，不需要加锁
  - 使用最小线程
    - 避免创建不需要的线程
  - 使用协程
    - 在单线程中实现多任务调度，在单线程中维持多个任务的切换



// todo 关于线程调试缺失



### 死锁

死锁的产生：多个线程相互等待对方释放锁资源

#### 示例

死锁示例：2个线程分别获取2个锁

```java
package com.stt.thread.part01_base;
import java.util.concurrent.TimeUnit;
/**
 * 死锁示例
 * Created by Administrator on 2019/4/28.
 */
public class Ch01_DeadLockDemo {

	private static final String lock1 = "lock1";
	private static final String lock2 = "lock2";

	public static void main(String[] args) {
		// 线程1
		Thread t1 = new Thread(new Runnable() {
			@Override
			public void run() {
				synchronized (lock1){
					System.out.println("t1 obtain lock1");
					try {
						TimeUnit.SECONDS.sleep(1);
					} catch (InterruptedException e) {
						e.printStackTrace();
					}
					synchronized (lock2){
						System.out.println("t1 obtain lock2");
					}
				}
			}
		});
		// 线程2
		Thread t2 = new Thread(new Runnable() {
			@Override
			public void run() {
				synchronized (lock2){
					System.out.println("t2 obtain lock2");
					synchronized (lock1){
						System.out.println("t2 obtain lock1");
					}
				}
			}
		});
		t1.start();
		t2.start();
	}
}
// 输出
t1 obtain lock1
t2 obtain lock2
// 已经产生死锁
```



#### dump文件分析

使用在..\jdk1.8.0_101\bin目录下使用visualVM工具检测dump文件
![1556435973275](E:/java/note/thread/img/01.thread01.png)



##### 使用方式1

通过生成dump文件分析死锁

```shell
# 查找当前pid
E:\java\code\base-demo\practise>jps
15936 Jps
13352 Ch01_DeadLockDemo
# 生成dump文件
E:\java\code\base-demo\practise>jmap -dump:format=b,file=deadLock.dump 13352
Dumping heap to E:\java\code\base-demo\practise\deadLock.dump ...
Heap dump file created
```
点击文件->装入
![1556436623285](img\01.thread03.png)

装载成功后，可以看到线程死锁的情况

![1556437077961](img\01.thread04.png)



##### 使用方式2

在visualVM中选择死锁的进程，可以看到提示死锁产生，点击线程dump，可以看到死锁的细节

![1556436180966](img\01.thread02.png)

```shell
"Thread-1" #12 prio=5 os_prio=0 tid=0x0000000019880800 nid=0x3a00 waiting for monitor entry [0x000000001a5af000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at com.stt.thread.part01_base.Ch01_DeadLockDemo$2.run(Ch01_DeadLockDemo.java:39)
	- waiting to lock <0x000000078d427e10> (a java.lang.String)#此处可以看到等待锁的对象lock2
	- locked <0x000000078d427e48> (a java.lang.String) # 表示已经获得到锁lock1
	at java.lang.Thread.run(Thread.java:745)

   Locked ownable synchronizers:
	- None

"Thread-0" #11 prio=5 os_prio=0 tid=0x000000001987f800 nid=0x4090 waiting for monitor entry [0x000000001a87e000]
   java.lang.Thread.State: BLOCKED (on object monitor)
	at com.stt.thread.part01_base.Ch01_DeadLockDemo$1.run(Ch01_DeadLockDemo.java:27)
	- waiting to lock <0x000000078d427e48> (a java.lang.String)
	- locked <0x000000078d427e10> (a java.lang.String)
	at java.lang.Thread.run(Thread.java:745)

   Locked ownable synchronizers:
	- None
```



 参考

https://blog.csdn.net/hemin1003/article/details/71425209

jvm参考

https://www.cnblogs.com/happy-rabbit/p/6232581.html



### 避免死锁的方法

- 避免同一个线程同时获取多个锁
- 避免在一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源，防止多个锁嵌套
- 尝试使用定时锁，使用lock.tryLock(timeout)来代替内部锁机制
- 对于数据库锁，加锁和解锁必须在一个数据库连接中，否则会解锁失败



### 关于资源限制

> 在并发情况下，程序的运行速度受到计算机硬件资源和软件资源的限制，如网络访问的带宽限制，数据库访问IO限制等

- 资源限制引发的问题

  将串行执行的部分转换为并行执行，但是当并行的代码执行的是资源受限制的部分，依然会变成串行执行，如果并发量大的话（增加了上下文切换和资源调度时间），反而会执行变慢。

- 硬件资源限制解决

  增加机器，使用集群进行处理，多台机器，每台机器处理一块数据，处理完成后进行合并

- 软件资源限制解决

  使用资源连接池，将连接资源进行复用。



## 并发机制底层原理



### volatile 实现与原理

> 轻量级的synchronized，多线程中保证了共享变量的可见性
> 可见性：当一个线程修改一个共享变量时，另一个线程可以读取到这个修改的值
> 使用volatile变量修饰符不会引起线程上下文的切换和调度，比synchronized性能更高，如何正确的使用volatile是关键

- 定义：为了保证共享变量可以被其他线程准确，一致的更新，线程要通过排他锁单独获取这个变量，当一个字段被声明为volatile，java内存模型确保所有线程看到这个变量是一致的

参考：https://blog.csdn.net/qq_26222859/article/details/52235930



#### 原理分析

```java
// instance 使用 volatile 修饰
instance = new Singleton();
// 编译之后
0x01a3de1d: movb $0×0,0×1104800(%esi);0x01a3de24: lock addl $0×0,(%esp);
```

重点是0x01a3de24: lock addl $0×0,(%esp); 作用在cpu中如下：

- **当前**==处理器缓存行==的数据写回到==系统内存==中
- 写回操作导致其他cpu里缓存行缓存该内存的地址无效，需要重新获取，从而保证可见性



##### 关于cpu缓存行和内存

- 为了提高cpu处理速度，处理器不直接和内存进行数据交互，而是先将内存的数据缓存到cpu的缓存（cpu缓存行 ，cpu有多个缓存行， 如L1 L2 L3等）
- cpu对缓存行中的数据进行交互
- 如果声明了变量为volatile修饰，那么对该变量进行写操作，那么JVM会增加一个lock#指令，导致该变量在cpu的缓存行的数据写回到系统内存中。
- cpu有缓存一致性协议
  - 每个cpu通过嗅探在总线上传播的数据检查自己的缓存值是否过期，缓存值发现对应的内存地址被修改，会将该缓存行的数据设置为无效
  - cpu对缓存行的无效的数据，访问时，会重新从内存中拉取到缓存行中，保证是最新的。



##### volatile实现原则

- 汇编lock前缀指令会使cpu缓存行中的数据写回到内存中
  - 使用lock#前缀时，处理器==独占==任何共享内存
  - lock#前缀在不同cpu的锁的方式不同
    - 锁缓存
    - 锁总线，开销大

	> 在修改内存操作时，使用LOCK前缀去调用加锁的读-修改-写操作，这种机制用于多处理器系统中处理器之间进行可靠的通讯，具体描述如下：
（1）在Pentium和早期的IA-32处理器中，LOCK前缀会使处理器执行当前指令时产生一个LOCK#信号，这种总是引起显式总线锁定出现
（2）在Pentium4、Inter Xeon和P6系列处理器中，加锁操作是由高速缓存锁或总线锁来处理。如果内存访问有高速缓存且只影响一个单独的高速缓存行，那么操作中就会调用高速缓存锁，而系统总线和系统内存中的实际区域内不会被锁定。同时，这条总线上的其它Pentium4、Intel Xeon或者P6系列处理器就回写所有已修改的数据并使它们的高速缓存失效，以保证系统内存的一致性。如果内存访问没有高速缓存且/或它跨越了高速缓存行的边界，那么这个处理器就会产生LOCK#信号，并在锁定操作期间不会响应总线控制请求

- 一个处理器缓存回写到内存会导致其他处理器缓存无效

  - 通过嗅探一个处理器来检测其他处理器打算写内存的地址，当该地址处于共享状态，那么嗅探处理器将使他的缓存行无效，下次访问时，强行执行缓存行填充。



##### 流程分析

工作内存Work Memory其实就是对CPU寄存器和高速缓存的抽象，或者说每个线程的工作内存也可以简单理解为CPU寄存器和高速缓存。

那么当写两条线程Thread-A与Threab-B同时操作主存中的一个volatile变量i时，Thread-A写了变量i，那么：

- Thread-A发出LOCK#指令
- 发出的LOCK#指令锁总线（或锁缓存行），同时让Thread-B高速缓存中的缓存行内容失效
- Thread-A向主存回写最新修改的i

Thread-B读取变量i，那么：

- Thread-B发现对应地址的缓存行被锁了，等待锁的释放，缓存一致性协议会保证它读取到最新的值

由此可以看出，volatile关键字的读和普通变量的读取相比基本没差别，差别主要还是在变量的写操作上。



### synchronized 实现与原理

> 重量级锁，每个对象都可以作为锁

- 对于普通同步方法，锁是当前实例对象
- 对于静态同步方法，锁是当前类的Class对象
- 对于同步方法块，锁是Synchronized括号中配置的对象



#### JVM使用monitor对象实现方法和代码块同步

- monitorenter指令在编译后插入到同步代码块开始的位置
- monitorexit指令在编译后插入到同步代码块结束和异常的位置
- monitorenter和monitorexit必须配对
- 每个对象都有一个对应的monitor对象
- 当一个monitor对象被持有时，线程执行到monitoreneter会尝试获取该monitor的所有权---尝试获取对象锁



#### java对象头存储synchronized锁信息

- java对象头有一个Mark Word存储HashCode，分代年龄，锁标记位，如果jvm是32位，那么Mark Word大小是32bit，64位是64bit

- 以32位为例，Mark Word组成与状态如下

| 锁状态   | 29bit                    | 1bit 是否偏向锁 | 2bit 锁标志位 |
| -------- | ------------------------- | --------------- | ------------- |
| 无锁状态 | 对象的hashCode(25bit)对象的分代年龄(4bit) | 0 | 01            |
| 轻量级锁 | 指向栈中锁记录的指针 |  | 00            |
| 重量级锁 | 指向互斥量(重量级锁)的指针 |  | 10            |
| GC标记   | 空 |  | 11            |
| 偏向锁   | 线程ID(23bit),Epoch(2bit)对象的分代年龄(4bit) | 1 | 01            |



#### 锁的升级

JDK1.6 为了减少获取和释放锁的性能消耗，增加偏向锁和轻量级锁

锁升级

- 从低到高：无锁状态 –> 偏向锁 –>轻量级 –>重量级
- 锁可以升级，但不能降级



#### 偏向锁

- 大多情况下，锁的竞争不是特别激烈，同一个线程可以获取到多次锁，为了减少获取锁的代价，引入偏向锁
- 当一个线程第一次访问同步代码块获取锁时，会在MarkWord中记录线程ID
- JDK7默认开启，如果关闭需要使用：-XX:- UseBiasedLocking=false，则程序会默认进入轻量级锁状态



##### 锁的获取

当该线程再次访问同步代码块的时候，如果MarkWord中的记录线程ID是当前线程，可以直接获取到锁，如果不是，那么判断偏向锁标志位是否是1，是0则需要进行CAS操作竞争锁，如果是1，则将使用CAS将对象头的偏向锁指向当前线程



##### 锁的撤销

等到==锁竞争==才进行锁的释放，否则一直记录原先线程持有，提升了性能

撤销操作：等到全局安全点（该时间片没有代码执行），暂停有偏向锁的线程，检查该线程是否存活，如果该线程不存活，修改锁为无锁状态；如果线程存活，==遍历偏向对象的锁记录==，通过记录判断是偏向其他线程还是重置为无锁状态或者升级为其他锁，然后唤醒暂停的线程。

![1556526760557](img\01.thread05.png)



#### 轻量级锁



##### 锁的获取

线程在执行同步代码块之前，JVM会在==当前线程==的栈帧中创建==存储锁记录==的空间，将对象头的MarkWord复制到当前线程的锁记录空间中（DisplacedMarkWord）；线程尝试使用==CAS==将对象头中的MarkWord替换为指向锁记录的指针，如果成功，表示获取到锁，如果失败，尝试使用==自旋锁==来获取锁。



##### 锁的撤销

解锁时，使用CAS将DisplacedMarkWord替换回对象头，成功，表示没有锁竞争，如果失败，锁升级为重量级锁



![1556527772256](E:\java\note\thread\img\01.thread06.png)

由于自旋锁会消耗cpu，为了避免无效的自旋锁，一旦升级为重量级锁，就不会恢复为轻量级锁。在重量级锁情况下，如果锁被占用，当前线程会进行==阻塞，等待唤醒==。



#### 锁对比

| 锁       | 优点                                                       | 缺点                                              | 场景                               |
| -------- | ---------------------------------------------------------- | ------------------------------------------------- | ---------------------------------- |
| 偏向锁   | 加锁和解锁不需要额外的开销，和执行非同步方法只有纳秒的差别 | 如果线程间存在锁竞争，会有额外的锁撤销资源        | 只有一个线程访问同步块信息         |
| 轻量级锁 | 锁竞争不会阻塞，提高了程序响应速度（因为自旋）             | 如果始终得不到锁，那么会一直自旋操作，消耗cpu资源 | 追求响应时间，同步块执行速度非常快 |
| 重量级锁 | 线程竞争不使用自旋锁，不会消耗cpu资源                      | 线程阻塞，响应时间慢                              | 追求吞吐量，同步代码块执行时间长   |



### 原子操作实现原理

> 不可中断的一个或者一系列操作

术语解释

| 名称         | 英文                   | 解释                                                         |
| ------------ | ---------------------- | ------------------------------------------------------------ |
| 缓存行       | cache line             | 缓存最小操作单位                                             |
| 比较并交换   | compare and swap       | CAS操作，一个旧值，一个新值，操作期间比较旧值有没有变化，没有变化则更换，有变化则不更换 |
| cpu流水线    | cpu pipeline           | cpu在一个时钟周期内完成一条指令，该指令含有多个操作          |
| 内存顺序冲突 | memory order violation | 一般由假共享引起，多个cpu同时修改同一个缓存行的不同部分而引起其中一个cpu操作无效，出现冲突时，清空cpu流水线操作 |



#### 如何实现原子操作

> 前提：cpu保证内存操作的原子性，从内存中读取和写入==一个字节==是原子操作
> 最新的处理器可以保证对一个缓存行进行16/32/64bit操作是原子性的
> 但是复杂的内部操作是不能保证原子性的（跨总线宽度，跨多个缓存行，跨页表访问）
>
> 因此cpu使用总线锁和缓存锁来保证原子性操作



##### 总线锁 Lock#

多个线程同时操作共享变量，改写的操作不是原子性的，得到值与期望值可能不一致
可能多个线程从各自的缓存中读取变量，分别操作，分别写入到内存中
此时就需要提供一个总线锁使用处理器提供的Lock#信号给来处理，当一个cpu在总线上输出此信号，其他的处理请求被==阻塞==，该共享内存被cpu独占



##### 缓存锁

总线锁的问题：把cpu和内存之间的通信锁住了，锁定期间，其他cpu不能与内存进行通信，开销较大
从而在某些场合使用缓存锁代替总线锁，而缓存锁是保证==某个内存地址操作==是原子性的，

